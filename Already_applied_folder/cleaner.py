import csv
import os

# ğŸ—‚ File path
file_path = "./already_applied.csv"
temp_file = "./temp_already_applied.csv"

# ğŸ”„ Set to track unique links
unique_links = set()
duplicates = []

# ğŸ“– Read existing file and remove duplicates
if os.path.exists(file_path):
    with open(file_path, "r", encoding="utf-8") as infile, open(temp_file, "w", encoding="utf-8", newline="") as outfile:
        reader = csv.reader(infile)
        writer = csv.writer(outfile)

        for row in reader:
            if row:  # Ensure row is not empty
                link = row[0]
                if link not in unique_links:
                    unique_links.add(link)
                    writer.writerow(row)
                else:
                    duplicates.append(link)

    # ğŸ“Œ Replace original file with cleaned file
    os.replace(temp_file, file_path)

    # ğŸ“Š Console output
    print(f"\nâœ… Duplicate Removal Completed!")
    print(f"ğŸ“Œ Total Unique Links: {len(unique_links)}")
    print(f"âŒ Total Duplicates Removed: {len(duplicates)}")

    if duplicates:
        print("\nğŸ—‘ Removed Links:")
        for i, link in enumerate(duplicates, start=1):
            print(f"{i}. {link}")
else:
    print("âš ï¸ File 'already_applied.csv' not found!")
